{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb36c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GumbelSelectorWeighted(nn.Module):\n",
    "#     def __init__(self, input_size=6, k=3):\n",
    "#         super().__init__()\n",
    "#         self.k = k\n",
    "#         self.logits = nn.Parameter(torch.randn(input_size))  # per la selezione\n",
    "#         self.output_weights = nn.Parameter(torch.rand(k))    # pesi appresi\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a3c17",
   "metadata": {},
   "source": [
    "#   Introduzione su (nn.Module)\n",
    "\n",
    "osservando la prima riga del codice troviamo **class GumbelSelectorWeighted(nn.moduel)**\n",
    "\n",
    "    nn.Module è una classe base fornita dalla libreria PyTorch\n",
    "- Rappresenta un  modulo (o un blocco) di una rete neurale. Un modulo può esse pensato come un contenutore per un insieme di parametri e funzioni\n",
    "- Che possono esser utilizzati per elaborare i dati. Quando si crea una nuova classe che eredita da nn.Module, come in questo caso, \n",
    "- si sta creando un nuovo tipo di modulo che può essere utilizzato nella rete neurale. La classe GumbelSelectorWeighted contiene le definizioni \n",
    "- dei parametri e delle funzioni necessarie per implementare un selettore di pesi utilizzando la distribuzione di Gumbel.\n",
    " \n",
    "\n",
    "_\n",
    "\n",
    "    def __init__(self, input_size=6, k=3):\n",
    "- È il costruttore della classe: viene eseguito quando crei il modello.\n",
    "- input_size=6: il numero totale di input (es. [a1, ..., a6])\n",
    "- k=3: quanti input vuoi selezionare automaticamente (es. 3 tra 6)\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "    super().__init__()\n",
    "    self.k = k\n",
    "\n",
    "- Chiama il costruttore della classe madre (nn.Module)\n",
    "- Necessario per inizializzare correttamente la rete in PyTorch.\n",
    "- Salva k come attributo di istanza, così puoi accedervi ovunque nella classe.\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "    self.logits = nn.Parameter(torch.randn(input_size))\n",
    "\n",
    "- Qui viene creata una variabile allenabile (nn.Parameter) di lunghezza 6:\n",
    "- Rappresenta i punteggi (logits) per ciascun input.\n",
    "- Serve per decidere quali input selezionare\n",
    "-  Più alto il logit → più alta la probabilità che l’input venga scelto dal Gumbel-Softmax.\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "    self.output_weights = nn.Parameter(torch.rand(k))\n",
    "\n",
    "- Questa è una seconda variabile allenabile:\n",
    "- È un vettore di lunghezza k (es. 3) → uno per ogni input selezionato\n",
    "- Rappresenta i pesi che verranno applicati agli input scelti.\n",
    "-  Se scegli [a1, a4, a6], allora output_weights sarà qualcosa tipo [1.4, 2.1, 0.9] da moltiplicare per i rispettivi valori.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab75258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def forward(self, x, temperature=0.5):\n",
    "#         # 1. Gumbel softmax campionamento\n",
    "#         probs = gumbel_softmax(self.logits.unsqueeze(0), temperature=temperature, hard=False)\n",
    "#         _, topk_indices = torch.topk(probs, self.k, dim=1)\n",
    "\n",
    "#         # 2. Estrai solo i k input selezionati\n",
    "#         selected_inputs = x[:, topk_indices[0]]  # shape: (batch_size, k)\n",
    "\n",
    "#         # 3. Applica i pesi solo ai selezionati\n",
    "#         weighted_sum = (selected_inputs * self.output_weights).sum(dim=1, keepdim=True)\n",
    "\n",
    "#         return weighted_sum, topk_indices, self.output_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ebaf1a",
   "metadata": {},
   "source": [
    "_\n",
    "\n",
    "    def forward(self, x, temperature=0.5)\n",
    "- **Questo è il metodo che calcola l’output del modello.**\n",
    "- x: input (es. [[a1, a2, ..., a6]])\n",
    "- temperature: controlla quanto è \"netta\" la selezione dei 3 input (più bassa = più netta)\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "    probs = gumbel_softmax(self.logits.unsqueeze(0), temperature=temperature, hard=False)\n",
    "- **self.logits sono i punteggi appresi per ciascun input.**\n",
    "- gumbel_softmax(...) → crea una distribuzione morbida (quasi probabilità) su 6 input\n",
    "-  Alla fine ottieni un vettore di 6 numeri (sommati = 1), es: \n",
    "- **[0.01, 0.45, 0.02, 0.10, 0.39, 0.03]**\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "\n",
    "    _, topk_indices = torch.topk(probs, self.k, dim=1)\n",
    "- Usa torch.topk per prendere gli indici dei k input migliori, cioè i 3 più probabili.\n",
    "- Se probs = [0.01, 0.45, 0.02, 0.10, 0.39, 0.03], restituisce:\n",
    "- **topk_indices = [1, 4, 3] → significa: scegli a2, a5, a4**\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "    selected_inputs = x[:, topk_indices[0]]  # shape: (batch_size, k)\n",
    "- seleziona i valori del tensore x : topk_indices = [1, 4, 3]    →    selected_inputs = [[8, 33, 23]]\n",
    "\n",
    "\n",
    "\n",
    "_\n",
    "\n",
    "    weighted_sum = (selected_inputs * self.output_weights).sum(dim=1, keepdim=True)\n",
    "-  Moltiplica ogni input selezionato per il suo peso appreso (output_weights)\n",
    "- Poi li somma → questo è il valore stimato di S\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ESEMPIO PRATICO\n",
    "- **x = [[10, 8, 15, 23, 33, 21]]** →\n",
    "    - **topk_indices = [1, 4, 3]** → \n",
    "        - **selected_inputs = [8, 33, 23]** → \n",
    "            - **output_weights = [1.2, 0.8, 0.5]** → \n",
    "                - **weighted_sum = 8 x 1.2 + 33 x 0.8 + 23 x 0.5**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
